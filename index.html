</nav>
		<div class="container">
    		<div class="blurb">
        				
			<h1> Anbang Yao (姚安邦)</h1>
			<p> Senior Staff Research Scientist (研究总监), <em>Intel Labs China</em>. </p> 			
			<p> Research Interest: Computer Vision, Deep Learning and Machine Learning.
			<p> E-mail: firstname dot lastname at intel dot com. </p>
			
			<p> <img src="https://simplecore.intel.com/ai/wp-content/uploads/sites/69/Anbang_Yao-300x300.jpg" width=300, algin=left, border=0> </p>			

			<p> <b>Internship is opening:</b> if you are interested on it, please drop me an email.</p>
			
			<h1> Short Bio: </h1>
			<p> Anbang Yao got his Ph.D. degree from Tsinghua University in Jan. 2010. He is currently a Senior Staff Research Scientist at Intel Labs China where he leads the research efforts on 
				2D/3D scene understanding, deep neural network designing and compression, emotion analysis, and so forth. He has 60+ PCT/US patent applications got granted/filed, which are widely
				used in Intel AI related HW designs and SW applications. As the first/corresponding author, he has published 20+ top-tier research papers in NIPS, ICLR, CVPR, ICCV, ECCV, TIP, PR and etc.
				He was recognized with ~40 Awards at Intel, including 1 Intel Global Inventor (2018, 1 out of ~10000 employees of Intel China), 3 Intel Labs Gordy Awards (2014/2015/2016), Intel Labs Top-1 Inventor of the Year (2017), 2 Intel China Awards (2016/2017), 1 Employee of the Year Award of Intel China (2017) and 1 i360 Design Hero Award of Intel IOTG Asian Region (2017).</p>
			<h1> Selected Publications: </h1>
			<p> (* Interns mentored by me, + Corresponding author)	
			<p> Efficient Semantic Scene Completion Network with Spatial Group Convolution. </p>
                        <p> Jiahui Zhang(*), Hao Zhao(*), <b>Anbang Yao</b>(+), Yurong Chen, Li Zhang and Hongen Liao.</p>
			<p> ECCV 2018 (<b>Oral</b>). </p>
			<p> Explicit Loss-Error-Aware Quantization for Low-Bit Deep Neural Networks. </p>
                        <p> Aojun Zhou(*), <b>Anbang Yao</b>(+), Kuan Wang and Yurong Chen.</p>
			<p> CVPR 2018. </p>	
			<p> Incremental Network Quantization: Towards Lossless CNNs with Low-Precision Weights. </p>
                        <p> Aojun Zhou(*), <b>Anbang Yao</b>(+), Yiwen Guo, Lin Xu and Yurong Chen.</p>
			<p> ICLR 2017. </p>				
			<p> Decoder Network over Lightweight Reconstructed Feature for Fast Semantic Style Transfer. </p>
                        <p> Ming Lu(*), Hao Zhao(*), <b>Anbang Yao</b>(+), Feng Xu, Yurong Chen and Li Zhang.</p>
			<p> ICCV 2017. </p>
			<p> RON: Reverse Connection with Objectness Prior Networks for Object Detection. </p>
                        <p> Tao Kong(*), Fuchun Sun, <b>Anbang Yao</b>(+), Huaping Liu, Ming Lu(*) and Yurong Chen.</p>
			<p> CVPR 2017. </p>
			<p> Physics Inspired Optimization on Semantic Transfer Features: An Alternative Method for Room Layout Estimation. </p>
                        <p> Hao Zhao(*), Ming Lu(*), <b>Anbang Yao</b>(+), Yurong Chen and Li Zhang..</p>
			<p> CVPR 2017. </p>
			<p> Network Sketching: Exploiting Binary Structure in Deep CNNs. </p>
                        <p> Yiwen Guo, <b>Anbang Yao</b>, Hao Zhao(*) and Yurong Chen.</p>
			<p> CVPR 2017. </p>	
			<p> Learning Supervised Scoring Ensemble for Emotion Recognition in the Wild. </p>
                        <p> Ping Hu, Dongqi Cai, Shandong Wang, <b>Anbang Yao</b>(+, project leader) and Yurong Chen.</p>
			<p> ACM ICMI 2017 (<b>Oral, Winner of EmotiW-AFEW 2017 out of 100+ Teams</b>). </p>	
			<p> Dynamic Network Surgery for Efficient DNNs. </p>
                        <p> Yiwen Guo(*), Anbang Yao(+) and Yurong Chen.</p>
			<p> NeurIPS 2016. </p>	
			<p> HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection. </p>
                        <p> Tao Kong(*), <b>Anbang Yao</b>(+), Yurong Chen and Fuchun Sun.</p>
			<p> CVPR 2018 (<b>Spotlight</b>). </p>	
			<p> HoloNet: Towards Robust Emotion Recognition in the Wild. </p>
                        <p> <b>Anbang Yao</b>(+), Dongqi Cai, Ping Hu, Shandong Wang, Liang Sha and Yurong Chen.</p>
			<p> ACM ICMI 2016(<b>Oral, 1-st Runner-up of EmotiW-AFEW 2016 out of ~100 Teams</b>). </p>	
			<p> Capturing AU-Aware Facial Features and Their Latent Relations for Emotion Recognition in the Wild. </p>
                        <p> <b>Anbang Yao</b>(+), Junchao Shao(*), Ningning Ma(*) and Yurong Chen.</p>
			<p> ACM ICMI 2015(<b>Oral, Winner of EmotiW-AFEW 2015 out of 75 Teams</b>). </p>
			<p> Robust Face Representation Using Hybrid Spatial Feature Interdependence Matrix. </p>
                        <p> <b>Anbang Yao</b>(+) and Shan Yu.</p>
			<p> IEEE Trans. Image Processing, 2013. </p>	
			<p> A Compact Association of Particle Filtering and Kernel Based Object Tracking. </p>
                        <p> <b>Anbang Yao</b>(+), Xinggang Lin, Guijin Wang and Shan Yu.</p>
			<p> Pattern Recognition, 2012. </p>
			<p> An Incremental Bhattacharyya Dissimilarity Measure for Particle Filtering. </p>
                        <p> <b>Anbang Yao</b>(+), Guijin Wang, Xinggang Lin and Xiujuan Chai.</p>
			<p> Pattern Recognition, 2010. </p>	
			<p> Kernel Based Articulated Object Tracking with Scale Adaptation and Model Update. </p>
                        <p> <b>Anbang Yao</b>(+), Guijin Wang, Xinggang Lin and Hao Wang.</p>
			<p> ICASSP, 2008. </p>				
			
			<h1> Current and Past Interns:</h1>
                        <li> <a href="/">Dawei Sun (Tsinghua University).</a></li>	
			<li> <a href="/">Duo Li (Tsinghua University).</a></li>	
			<li> <a href="/">Jiahui Zhang (Tsinghua University).</a></li>	
			<li> <a href="/">Aojun Zhou (CASIA).</a></li>
			<li> <a href="/">Ming Lu (Tsinghua University).</a></li>	
			<li> <a href="/">Hao Zhao (Tsinghua University).</a></li>	
		        <li> <a href="/">Kuan Wang (Tsinghua University).</a></li>			
			<li> <a href="/">Tao Kong (Tsinghua University).</a></li>
			<li> <a href="/">Wenbing Huang (Tsinghua University).</a></li>
		        <li> <a href="/">Yun Ren (Beihang University).</a></li>
			<li> <a href="/">Yao Cheng (Peking University).</a></li>
			<li> <a href="/">Peixian Wu (Tsinghua University).</a></li>
			<li> <a href="/">Ruoyan Wang (Dalian University of Technology).</a></li>
			<li> <a href="/">Yuhang Wang (CASIA).</a></li>
			<li> <a href="/">Yunlong Bian (Beijing University of Posts and Telecommunications).</a></li>
			<li> <a href="/">Ningning Ma (Tsinghua University).</a></li>
			<li> <a href="/">Junchao Shao (Beihang University).</a></li>
			<li> <a href="/">Yiwen Guo (Tsinghua University).</a></li>	
			
			<h1>Awards:</h1>	
                        <li><a href="/">Intel Global Inventor 2018, Only 1 out of ~10000 Employees of Intel China.</a></li>
			<li><a href="/">Employee of the Year 2017, Intel China.</a></li>	
			<li><a href="/">Intel China Award 2017, Highest Team Award of Intel China.</a></li>
			<li><a href="/">Inventor of 2017, Top-1 out of ~700 Researchers across Intel Labs Globally.</a></li>
			<li><a href="/">Intel i360 Design Hero Award 2017, Highest Business Award of Intel IOTG Asian Region.</a></li>
			<li><a href="/">Intel Labs Academy Award 2016 (a.k.a Gordy Award,戈登·摩尔奖), Highest Annual Research Award to 6 out of All Projects across Intel Labs Globally. </a></li>
			<li><a href="/">Intel China Award 2016.</a></li>			
			<li><a href="/">Intel Labs Academy Award 2015 (a.k.a Gordy Award,戈登·摩尔奖), Highest Annual Research Award to 6 out of All Projects across Intel Labs Globally. </a></li>			
			<li><a href="/">Intel Labs Academy Award 2014 (a.k.a Gordy Award,戈登·摩尔奖), Highest Annual Research Award to 6 out of All Projects across Intel Labs Globally. </a></li>    		
			<li><a href="/">Tsinghua-JiangZhen Scholarship 2009, First Class, Highest Honor of School of Information Science and Technology of Tsinghua University.</a></li>
		        <li><a href="/">Tsinghua-Toshiba Scholarship 2008, First Class.</a></li>
                        <li><a href="/">Tsinghua-German Scholarship 2008, Ranked No. 13 among all students who learn "Deutsch" in Tsinghua University.</a></li>			
		        <li><a href="/">Tsinghua-AHaiFa Scholarship 2005, First Class.</a></li>				
		</div><!-- /.blurb -->
		</div><!-- /.container -->
		<footer>
    		<ul>			</ul>
		</footer>
	</body>
</html>
