---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Short Bio
=====

Anbang Yao got his Ph.D. degree from Tsinghua University in 2010. He is currently a PE (Principal Engineer), Principal Research Scientist at Intel Labs China where he leads the research efforts on developing omni-scale high-performance intelligent vision systems. He has over 80 PCT/US/EP patent applications got granted/filed, which are widely used in Intel AI related HW designs (such as Intel® Movidius™ Neural Compute Sticks and Intel® Arria® 10 SoC FPGAs) and SW applications (such as Intel® RealSense™ SDK and Intel® Distribution of OpenVINO™ Toolkit). As the first/corresponding author, he has published about 40 top-tier research papers in CVPR, ICCV, ECCV, NeurIPS, ICLR, and etc. He has been recognized with numerous Awards at Intel, such as Intel Innovator (the first and so far the only winner employee from China), 2 times of annual Intel China Awards, and 3 times of annual Intel Labs Gordy Awards (the highest annual research award named after Intel's co-founder Gordon Earle Moore, ***戈登·摩尔奖***). He also led the team and won the Winner of the prestigious EmotiW Challenges (held by ACM ICMI) in 2015/2017, beating out 74/100+ teams across the world. He demonstrated outstanding skills in mentoring interns, and many of them have already grown into top young researchers in the field.

<!--<font color="red">**Note**：We now have some internship positions. If you are interested in my research, please drop me an email. </font> -->
---
**<font color="red">News：</font>** 

<!--+ July 9th, 2020. One paper accepted to CVIU.-->
+ July 22nd, 2021. Our SNNs (Sub-bit Network Networks), the first work to compress and accelerate binary neural networks, is accepted to ICCV 2021.
+ December 14th, 2020. One paper accepted to TPAMI.
+ July 29th, 2020. One paper accepted to BMVC 2020.
+ July 25th, 2020. One full-length research paper accepted to ACM MM 2020.
+ July 3rd, 2020. Four papers accepted to ECCV 2020.
+ October 29th, 2019. One paper accepted to IJCV.
+ July 23rd, 2019. Three papers accepted to ICCV 2019.
+ February 25th, 2019. One paper accepted to CVPR 2019.
+ December 20th, 2018. Delivered an invited talk at Tsinghua University.
+ December 7th, 2018. Delivered an invited talk "Deep neural network compression and acceleration" at CDNNRIA Workshop in NeurIPS 2018. 
+ July 5th, 2018. Our SGC (Spatial Group Convolution) work is accepted as a full oral paper to ECCV 2018.
+ February 22nd, 2018. Our ELQ (Explicit Loss-error-aware Quantization) work is accepted to CVPR 2018.
+ July 17th, 2017. One paper accepted to ICCV 2017.
+ March 18th, 2017. Three papers accepted to CVPR 2017.
+ February 6th, 2017. Our INQ (Incremental Network Quantization) work is accepted to ICLR 2017.
+ August 12th, 2016. Our DNS (Dynamic Network Surgery) work is accepted to NIPS 2016.
+ March 1st, 2016. Our HyperNet work is accepted as a spotlight oral paper to CVPR 2016.

Selected Publications
=====

(\* Interns mentored by me, \+ Equal contribution, \# Corresponding author)

**2021**

<!-- <blockquote> -->
+ Sub-bit Neural Networks: Learning to Compress and Accelerate Binary Neural Networks.<br> Yikai Wang\*, Yi Yang, Fuchun Sun and Anbang Yao\#.<br> Accepted to <em>**International Conference on Computer Vision (ICCV)**</em>, 2021.<br> [<font color="blue">[Paper]</font>](https://yaoanbang.github.io/). [<font color="blue">[Code is coming soon]</font>](https://yaoanbang.github.io/).<br>
<!--</blockquote> -->

<!-- <blockquote> -->
+ Learning Two-View Correspondences and Geometry Using Order-Aware Network.<br> Jiahui Zhang\*\+, Dawei Sun\*\+, Zixin Luo, Anbang Yao, Hongkai Chen, Lei Zhou, Tianwei Shen, Yurong Chen, Long Quan and Hongen Liao.<br> To appear in <em>**IEEE Trans. on Pattern Analysis and Machine Intelligence**</em>, 2021.<br> [<font color="blue">[Paper]</font>](https://yaoanbang.github.io/). [<font color="blue">[Code]</font>](https://github.com/zjhthu/OANet).<br> 
<!-- </blockquote> -->

**2020**

+ Explicit Residual Descent for 3D Human Pose Estimation from 2D Joint Locations.<br> Yangyuxuan Kang\*+, Anbang Yao\#+, Shandong Wang, Ming Lu, Yurong Chen and Enhua Wu.<br> <em>**British Machine Vision Conference (BMVC)**</em>, 2020.<br> [<font color="blue">[Paper]</font>](https://www.bmvc2020-conference.com/assets/papers/0151.pdf). [<font color="blue">[Code]</font>](https://github.com/ky66111/ERD_3DPose).<br>
+ Learning Deep Multimodal Feature Representation with Asymmetric Multi-layer Fusion.<br> Yikai Wang\*, Fuchun Sun, Ming Lu and Anbang Yao\#.<br> <em>**ACM International Conference on Multimedia (ACM MM)**</em>, 2020.<br> [<font color="blue">[Paper]</font>](https://dl.acm.org/doi/10.1145/3394171.3413621). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ PSConv: Squeezing Feature Pyramid into One Compact Poly-Scale Convolutional Layer.<br> Duo Li\*, Anbang Yao\# and Qifeng Chen.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2020.<br> [<font color="blue">[Paper]</font>](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660613.pdf). [<font color="blue">[Code]</font>](https://github.com/d-li14/PSConv).<br>
+ Knowledge Transfer via Dense Cross-layer Mutual-distillation.<br> Anbang Yao\#\+ and Dawei Sun\*+.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2020.<br> [<font color="blue">[Paper]</font>](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600290.pdf). [<font color="blue">[Code]</font>](https://github.com/sundw2014/DCM).<br>
+ Resolution Switchable Networks for Runtime Efficient Image Classification.<br> Yikai Wang\*, Fuchun Sun, Duo Li\* and Anbang Yao\#.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2020.<br> [<font color="blue">[Paper]</font>](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600528.pdf). [<font color="blue">[Code]</font>](https://github.com/yikaiw/RS-Nets).<br>
+ Learning to Learn Parameterized Classification Networks for Scalable Input Images.<br> Duo Li\*, Anbang Yao\# and Qifeng Chen.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2020.<br> [<font color="blue">[Paper]</font>](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123740018.pdf). [<font color="blue">[Code]</font>](https://github.com/d-li14/SAN).<br>
+ Pointly-supervised Scene Parsing with Uncertainty Mixture.<br> Hao Zhao\*, Ming Lu\*, Anbang Yao, Yiwen Guo, Yurong Chen and Li Zhang.<br> <em>**Computer Vision and Image Understanding**</em>, vol 200, 103040, 2020.<br> [<font color="blue">[Paper]</font>](https://www.sciencedirect.com/science/article/pii/S1077314220300904). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ Learning to Draw Sight Lines.<br> Hao Zhao\*, Ming Lu\*, Anbang Yao, Yurong Chen and Li Zhang.<br> <em>**International Journal of Computer Vision**</em>, vol 128(5), pages 1076–1100, 2020.<br> [<font color="blue">[Paper]</font>](https://link.springer.com/article/10.1007/s11263-019-01263-4). [<font color="blue">[Demo]</font>](https://www.youtube.com/watch?v=81RZvvBv_fw).<br>

**2019**

+ HBONet: Harmonious Bottleneck on Two Orthogonal Dimensions.<br> Duo Li\*\+, Aojun Zhou\*\+ and Anbang Yao\#.<br> <em>**International Conference on Computer Vision (ICCV)**</em>, 2019.<br> [<font color="blue">[Paper]</font>](https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_HBONet_Harmonious_Bottleneck_on_Two_Orthogonal_Dimensions_ICCV_2019_paper.pdf). [<font color="blue">[Code]</font>](https://github.com/d-li14/HBONet).<br>
+ Learning Two-View Correspondences and Geometry Using Order-Aware Network.<br> Jiahui Zhang\*\+, Dawei Sun\*\+, Zixin Luo, Anbang Yao\#, Lei Zhou, Tianwei Shen, Yurong Chen, Long Quan and Hongen Liao.<br> <em>**International Conference on Computer Vision (ICCV)**</em>, 2019.<br> [<font color="blue">[Paper]</font>](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Learning_Two-View_Correspondences_and_Geometry_Using_Order-Aware_Network_ICCV_2019_paper.pdf). [<font color="blue">[Code]</font>](https://github.com/zjhthu/OANet).<br>
+ A Closed-form Solution to Universal Style Transfer.<br> Ming Lu\*, Hao Zhao\*, Anbang Yao\#, Yurong Chen, Feng Xu and Li Zhang.<br> <em>**International Conference on Computer Vision (ICCV)**</em>, 2019.<br> [<font color="blue">[Paper]</font>](https://openaccess.thecvf.com/content_ICCV_2019/papers/Lu_A_Closed-Form_Solution_to_Universal_Style_Transfer_ICCV_2019_paper.pdf). [<font color="blue">[Code]</font>](https://github.com/lu-m13/OptimalStyleTransfer).<br>
+ Deeply-Supervised Knowledge Synergy.<br> Dawei Sun\*\+, Anbang Yao\#\+, Aojun Zhou\* and Hao Zhao\*.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2019.<br> [<font color="blue">[Paper]</font>](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Deeply-Supervised_Knowledge_Synergy_CVPR_2019_paper.pdf). [<font color="blue">[Code]</font>](https://github.com/sundw2014/DKS).<br>

**2018**

+ Efficient Semantic Scene Completion Network with Spatial Group Convolution.<br> Jiahui Zhang\*, Hao Zhao\*, Anbang Yao\#, Yurong Chen, Li Zhang and Hongen Liao.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2018 (<font color="blue">Oral</font>).<br> [<font color="blue">[Paper]</font>](https://openaccess.thecvf.com/content_ECCV_2018/papers/Jiahui_Zhang_Efficient_Semantic_Scene_ECCV_2018_paper.pdf). [<font color="blue">[Code]</font>](https://github.com/zjhthu/SGC-Release).<br>
+ Explicit Loss-Error-Aware Quantization for Low-Bit Deep Neural Networks.<br> Aojun Zhou\*\+, Anbang Yao\#\+, Kuan Wang\* and Yurong Chen.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2018.<br> [<font color="blue">[Paper]</font>](https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Explicit_Loss-Error-Aware_Quantization_CVPR_2018_paper.pdf). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>

**2017**

+ Incremental Network Quantization: Towards Lossless CNNs with Low-Precision Weights.<br> Aojun Zhou\*\+, Anbang Yao\#\+, Yiwen Guo\+, Lin Xu and Yurong Chen.<br> <em>**International Conference on Learning Representations (ICLR)**</em>, 2017.<br> [<font color="blue">[Paper]</font>](https://arxiv.org/abs/1702.03044). [<font color="blue">[Code]</font>](https://github.com/AojunZhou/Incremental-Network-Quantization).<br>
+ Decoder Network over Lightweight Reconstructed Feature for Fast Semantic Style Transfer.<br> Ming Lu\*, Hao Zhao\*, Anbang Yao\#, Feng Xu, Yurong Chen and Li Zhang.<br> <em>**International Conference on Computer Vision (ICCV)**</em>, 2017.<br> [<font color="blue">[Paper]</font>](https://openaccess.thecvf.com/content_ICCV_2017/papers/Lu_Decoder_Network_Over_ICCV_2017_paper.pdf). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ RON: Reverse Connection with Objectness Prior Networks for Object Detection.<br> Tao Kong\*, Fuchun Sun, Anbang Yao\#, Huaping Liu, Ming Lu\* and Yurong Chen.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2017.<br> [<font color="blue">[Paper]</font>](https://arxiv.org/abs/1707.01691). [<font color="blue">[Code]</font>](https://github.com/taokong/RON).<br>
+ Physics Inspired Optimization on Semantic Transfer Features: An Alternative Method for Room Layout Estimation.<br> Hao Zhao\*, Ming Lu\*, Anbang Yao\#, Yurong Chen and Li Zhang.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2017.<br> [<font color="blue">[Paper]</font>](https://arxiv.org/abs/1707.00383). [<font color="blue">[Code]</font>](https://sites.google.com/view/st-pio/).<br>
+ Network Sketching: Exploiting Binary Structure in Deep CNNs.<br> Yiwen Guo, Anbang Yao, Hao Zhao\* and Yurong Chen.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2017.<br> [<font color="blue">[Paper]</font>](https://arxiv.org/abs/1706.02021). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ Learning Supervised Scoring Ensemble for Emotion Recognition in the Wild.<br> Ping Hu, Dongqi Cai, Shandong Wang, Anbang Yao\# (<font color="blue">project leader, conceived the idea and project</font>) and Yurong Chen.<br> <em>**ACM International Conference on Multimodal Interaction (ACM ICMI)**</em>, 2017 (<font color="blue">Oral, Winner of EmotiW-AFEW 2017, out of 100+ Teams</font>).<br> [<font color="blue">[Paper]</font>](https://dl.acm.org/doi/10.1145/3136755.3143009). [<font color="blue">[EmotiW 2017 Challenge Announcement]</font>](https://sites.google.com/site/emotiwchallenge/).<br>

**2016**

+ Dynamic Network Surgery for Efficient DNNs.<br> Yiwen Guo\*, Anbang Yao\# and Yurong Chen.<br> <em>**Neural Information Processing Systems (NIPS)**</em>, 2016.<br> [<font color="blue">[Paper]</font>](https://papers.nips.cc/paper/2016/file/2823f4797102ce1a1aec05359cc16dd9-Paper.pdf). [<font color="blue">[Code]</font>](https://github.com/yiwenguo/Dynamic-Network-Surgery).<br>
+ HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection.<br> Tao Kong\*, Anbang Yao\#, Yurong Chen and Fuchun Sun.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2016 (<font color="blue">Spotlight Oral</font>).<br> [<font color="blue">[Paper]</font>](https://openaccess.thecvf.com/content_cvpr_2016/papers/Kong_HyperNet_Towards_Accurate_CVPR_2016_paper.pdf). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ HoloNet: Towards Robust Emotion Recognition in the Wild.<br> Anbang Yao\#\+, Dongqi Cai\+, Ping Hu\+, Shandong Wang\+, Liang Sha\+ and Yurong Chen.<br> <em>**ACM International Conference on Multimodal Interaction (ACM ICMI)**</em>, 2016 (<font color="blue">Oral, 1<sup>st</sup> Runner-up of EmotiW-AFEW 2016, out of ~100 Teams</font>).<br> [<font color="blue">[Paper]</font>](https://dl.acm.org/doi/10.1145/2993148.2997639). [<font color="blue">[EmotiW 2016 Challenge Announcement]</font>](https://sites.google.com/site/emotiw2016/).<br>

**2015 and before**

+ Capturing AU-Aware Facial Features and Their Latent Relations for Emotion Recognition in the Wild.<br> Anbang Yao\#, Junchao Shao\*\+, Ningning Ma\*\+ and Yurong Chen.<br> <em>**ACM International Conference on Multimodal Interaction (ACM ICMI)**</em>, 2015 (<font color="blue">Oral, Winner of EmotiW-AFEW 2015, out of 75 Teams</font>).<br> [<font color="blue">[Paper]</font>](https://dl.acm.org/doi/10.1145/2818346.2830585). [<font color="blue">[EmotiW 2015 Challenge Announcement]</font>](https://cs.anu.edu.au/few/emotiw2015.html).<br>
+ Robust Face Representation Using Hybrid Spatial Feature Interdependence Matrix.<br> Anbang Yao\# and Shan Yu.<br> <em>**IEEE Trans. on Image Processing**</em>, vol 22(8), pages 3247–3259, 2013.<br> [<font color="blue">[Paper]</font>](https://ieeexplore.ieee.org/document/6459600). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ A Compact Association of Particle Filtering and Kernel Based Object Tracking.<br> Anbang Yao\#, Xinggang Lin, Guijin Wang and Shan Yu.<br> <em>**Pattern Recognition**</em>, vol 45(7), pages 2584-2597, 2012.<br> [<font color="blue">[Paper]</font>](https://www.sciencedirect.com/science/article/pii/S0031320312000374). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ An Incremental Bhattacharyya Dissimilarity Measure for Particle Filtering.<br> Anbang Yao\#, Guijin Wang, Xinggang Lin and Xiujuan Chai.<br> <em>**Pattern Recognition**</em>, vol 43(4), pages 1244-1256, 2010.<br> [<font color="blue">[Paper]</font>](https://www.sciencedirect.com/science/article/pii/S0031320309003689). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ Kernel Based Articulated Object Tracking with Scale Adaptation and Model Update.<br> Anbang Yao\#, Guijin Wang, Xinggang Lin and Hao Wang.<br> <em>**IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP)**</em>, 2008.<br> [<font color="blue">[Paper]</font>](https://ieeexplore.ieee.org/document/4517767). [<font color="blue">[Code]</font>](https://yaoanbang.github.io/).<br>

Current and Previous Interns
=====

I am really fortunate to be working with these amazingly talented students

+ Yuyang Liu (Tsinghua University)
+ Yangyuxuan Kang (ISCAS)
+ Zhaole Sun (Tsinghua University)
+ Ming Lu (Tsinghua University)
+ [Hao Zhao](https://scholar.google.com/citations?user=ygQznUQAAAAJ&hl=zh-CN) (Tsinghua University)
+ [Dawei Sun](https://scholar.google.com/citations?user=JwuiGckAAAAJ&hl=zh-CN) (Tsinghua University)
+ [Duo Li](https://scholar.google.com/citations?user=sUNEzWkAAAAJ&hl=zh-CN) (Tsinghua University)
+ [Aojun Zhou](https://scholar.google.com/citations?user=cC8lXi8AAAAJ&hl=zh-CN) (CASIA) 
+ [Jiahui Zhang](https://scholar.google.com/citations?user=l8YDfhgAAAAJ&hl=en) (Tsinghua University)
+ [Kuan Wang](https://scholar.google.com/citations?user=sGtYJngAAAAJ&hl=en) (Tsinghua University)
+ [Tao Kong](https://scholar.google.com/citations?user=kSUXLPkAAAAJ&hl=en) (Tsinghua University) 
+ [Wenbing Huang](https://scholar.google.com/citations?user=0yNkmO4AAAAJ&hl=zh-CN) (Tsinghua University) 
+ Yun Ren (Beihang University) 
+ Yao Cheng (Peking University) 
+ Peixian Hu (Tsinghua University) 
+ [Ruoyan Wang](https://www.linkedin.com/in/ruoyan-wang) (Dalian University of Technology) 
+ Yuhang Wang (CASIA)
+ Yunlong Bian (Beijing University of Posts and Telecommunications) 
+ [Ningning Ma](https://scholar.google.com/citations?user=vOAzYlcAAAAJ&hl=en&oi=sra) (Tsinghua University) 
+ Junchao Shao (Beihang University) 
+ [Yiwen Guo](https://scholar.google.com/citations?user=oi_lEwYAAAAJ&hl=en) (Tsinghua University)

Awards
=====

+ 1 Distinguished Invention Award in 2020, for strong merits to future Intel AI HW designs
+ 4 Intel China Quarterly Awards in 2017~2020
+ Intel Innovator 2018, 1 out of ~10000 Employees of Intel China, first and only winner employee of Intel China so far 
+ Intel China Employee of the Year Award 2017 	
+ Top-1 Inventor of Intel Labs 2017 (had 34 PCT/US patents approved and filed in one single year, and keeping the highest record so far), 1 out of ~800 Research Scientists of Intel Labs 
+ Intel i360 Design Hero Award 2017, Highest Annual Business Award of Intel IoTG Asian Region 
+ Intel China Award 2017/2016, Highest Annual Team Award of Intel China 
+ Gordy Award 2016/2015/2014 (named after Intel's co-founder Gordon Earle Moore), Highest Annual Research Award of Intel Labs
+ Tsinghua-JiangZhen Scholarship 2009, Highest Scholarship in School of Information Science and Technology 
+ Tsinghua-Toshiba Scholarship 2008, First Class	
+ Tsinghua-AHaiFa Scholarship 2005, First Class

Academic Service
=====

+ Conference Program Committee Member, Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, AAAI, BMVC, ACCV, WACV, ICMI, etc.
+ Journal Reviewer: IEEE-TPAMI, IJCV, IEEE-TNNLS, IEEE-TIP, IEEE-TSMC, IEEE-TC, etc.
