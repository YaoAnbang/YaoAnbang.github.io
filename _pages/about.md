---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Short Bio
=====

Anbang Yao is currently a Principal AI Scientist, also a Principal Engineer (known as PE, techncial leader recognized within Intel) at Intel Labs China where he leads the research efforts on developing omni-scale high-performance artificial intelligence systems. He got his Ph.D. degree from Tsinghua University in January 2010. He has over 120 PCT/US patent applications got granted/filed, which are broadly adopted in Intel AI HW Accelerators (Intel® NPU/VPU product line and Intel® Arria® Series FPGAs), HW Core Ultra AI IPs/Usages (Intel® Meteor/Arrow Lake for Laptops, Ultra-low-power Companion Die CVF paired with Meteor Lake Core Processors, and Intel® Xe GPUs), and SW Development Kits (Intel® Distribution of OpenVINO™ Toolkit and Intel® RealSense™ SDK). As the first/corresponding author, he has published over 45 top-tier research papers in ICLR, NeurIPS, ICML, AAAI, CVPR, ICCV, ECCV, TPAMI and etc. His works, such as INQ (Incremental Network Quantization) for neural network quantization, DNS (Dynamic Network Surgery) for sparse neural networks, HyperNet for efficient object detection and OANet (Order-Aware Network) for geometric correspondence learning, are among Most Influential ICLR/NeurIPS/CVPR/ICCV Papers in Google Scholar Metrics 2021/2022/2023/2024. He has been recognized with numerous Awards at Intel, such as Intel Innovator (the first and so far the only winner employee from China), Top-1 Inventor of Intel Labs (had 34 PCT/US patent applications approved in a single year, keeping the highest record so far), CTO recognition of exceptional contributions (31 sparse and low-bit AI inference IPs) to the Intel Core Ultra (code-named Meteor Lake) for laptops, 3 times of annual Intel Labs Gordy Awards (the highest annual research award named after Intel's co-founder Gordon Earle Moore, ***戈登·摩尔奖***), and 2 times of annual Intel China Awards. He also led the team and won the Winner of the prestigious EmotiW Challenges (held by ACM ICMI) in 2015/2017, beating out 74/100+ teams across the world. He demonstrated outstanding skills in mentoring interns/team members, and many of them have already grown into top young researchers in the field. He served as an Area Chair or a Senior PC to NeurIPS, ICML and AAAI for multiple times, and was also recognized with Top Reviewer for NeurIPS 2019/2022 and Notable Area Chair for NeurIPS 2024.

<font color="Crimson">**Note**: If you are interested in research internship positions, please drop me an email. </font>
---
**<font color="Crimson">News：</font>** 

+ June<!--8th-->, 2025. Our paper ACE-OF-SPADEs, a SoC accelerator for spatially sparse 3D DNNs, is accepted to ACM TECS .
+ May<!--1st-->, 2025. Our paper Morse, which presents a simple dual-sampling framework to losslessly accelerate any type of diffusion models such as the Stable Diffusion family, is accepted to ICML 2025.
+ February<!--17th-->, 2025. I will be serving as an Area Chair for NeurIPS 2025.
+ December<!--15th-->, 2024. I will be serving as an Area Chair for ICML 2025.
+ December<!--12th-->, 2024. I am awarded as a Notable Area Chair from NeurIPS 2024.  
+ September<!--26th-->, 2024. Our paper ScaleKD, a compelling work that could transfer the scalable property of pre-trained large vision transformer models to smaller target models of any type without need of large-scale pre-training data, is accepted to NeurIPS 2024.
+ May<!--2nd-->, 2024. Our work KernelWarehouse, which advances dynamic convolution research towards substantially better parameter efficiency and representation power, is accepted to ICML 2024.
+ March<!--28th-->, 2024. I will be serving as an Area Chair for NeurIPS 2024.
+ February<!--27th-->, 2024. Our paper SSD-KD, the first work for super-fast and high-performance data-free knowledge distillation with a new concept of "small scale data inversion", is accepted to CVPR 2024. 
+ September<!--22nd-->, 2023. Our paper Af-DCD, a new augmentation-free dense contrastive distillation framework for efficient semantic segmentation, is accepted to NeurIPS 2023. 
+ April<!--25th-->, 2023. Our paper Ske2Grid, a progressive representation learning framework conditioned on transforming human skeleton graph into an up-sampled grid representation for skeleton based action recognition, is accepted to ICML 2023. 
+ February<!--28th-->, 2023. Our paper Sparks is accepted to CVPR 2023.  <!--scored with 5/5/4-->
+ January<!--21st-->, 2023. Our paper NORM, the first knowledge distillation work for N-to-One Rrepresentation Matching, is accepted to ICLR 2023. 
+ January<!--11th-->, 2023. Our work Grid Convolution is accepted to AAAI 2023 as an oral paper. <!--+ November 19th, 2022. Our work Grid Convolution is accepted to AAAI 2023 as an oral paper.--> 
+ October<!--13th-->, 2022. I am awarded as a Top (a.k.a. Outstanding) Reviewer from NeurIPS 2022. 
+ June<!--1st-->, 2022. The journal version of our work OANet is published by TPAMI.
+ January<!--21st-->, 2022. Our work Omni-Dimensional Dynamic Convolution scored with 8/8/8/6 is accepted to ICLR 2022 as a Spotlight paper.
+ September<!--28th-->, 2021. Our paper for efficient video action recognition is accepted to NeurIPS 2021.
+ August<!--11th-->, 2021. I will be serving as a Senior Program Committee (SPC, akin to Area Chair to NeurIPS) member for AAAI 2022.
+ July<!--22nd-->, 2021. Our SNNs (Sub-bit Network Networks), the first work to compress and accelerate binary neural networks, is accepted to ICCV 2021.<!--+ December 14th, 2020. One paper accepted to TPAMI.--><!--+ July 29th, 2020. One paper accepted to BMVC 2020.-->
+ July<!--25th-->, 2020. One full-length research paper accepted to ACM MM 2020.<!--+ July 9th, 2020. One paper accepted to CVIU.-->
+ July<!--3rd-->, 2020. Our works DCM (Dense Cross-layer Mutual-distillation) and RS-Nets (Resolution Switchable Networks) together with the other two works accepted to ECCV 2020.<!--+ October 29th, 2019. One paper accepted to IJCV.-->
+ September<!--6th-->, 2019. I am recognized as a Top Reviewer from NeurIPS 2019. 
+ July<!--23rd-->, 2019. Three papers accepted to ICCV 2019.
+ February<!--25th-->, 2019. Our work DKS (Deeply-supervised Knowledge Synergy) is accepted to CVPR 2019.
+ December<!--20th-->, 2018. Delivered an invited talk at Tsinghua University.
+ December<!--7th-->, 2018. Delivered an invited talk "Deep neural network compression and acceleration" at CDNNRIA Workshop in NeurIPS 2018. 
+ July<!--5th-->, 2018. Our work SGC (Spatial Group Convolution) is accepted as a full oral paper to ECCV 2018.
+ February<!--22nd-->, 2018. Our work ELQ (Explicit Loss-error-aware Quantization) is accepted to CVPR 2018.
+ July<!--17th-->, 2017. One paper accepted to ICCV 2017.
+ March<!--18th-->, 2017. Three papers accepted to CVPR 2017.
+ February<!--6th-->, 2017. Our work INQ (Incremental Network Quantization) is accepted to ICLR 2017.
+ August<!--12th-->, 2016. Our work DNS (Dynamic Network Surgery) is accepted to NIPS 2016.
+ March<!--1st-->, 2016. Our work HyperNet is accepted as a spotlight oral paper to CVPR 2016.


Latest Manuscripts  
=====
(\* Interns or team/project members mentored by me, \+ Equal contribution, \# Corresponding author)

+ NOAH: Learning Pairwise Object Category Attentions for Image Classification.<br> Chao Li\*, Aojun Zhou and Anbang Yao\#.<br><em>**arXiv preprint, 2024**</em>.<br> [<font color="DodgerBlue">[Manuscript]</font>](https://arxiv.org/abs/2402.02377).[<font color="DodgerBlue">[Code]</font>](https://github.com/OSVAI/NOAH).<br>

Selected Publications
=====
**2025**
+ Morse: Dual-Sampling for Lossless Acceleration of Diffusion Models.<br> Chao Li\*, Jiawei Fan\* and Anbang Yao\#.<br><em>**International Conference on Machine Learning (ICML)**</em>, 2025.<br>[<font color="DodgerBlue">[Paper]</font>](https://arxiv.org/abs/2506.18251).[<font color="DodgerBlue">[Code]</font>](https://github.com/deep-optimization/Morse).<br> 

**2024**
<!-- <blockquote> -->
+ ScaleKD: Strong Vision Transformers Could Be Excellent Teachers.<br> Jiawei Fan\*, Chao Li\*, Xiaolong Liu\*, and Anbang Yao\#.<br><em>**Conference on Neural Information Processing Systems (NeurIPS)**</em>, 2024.<br> [<font color="DodgerBlue">[Paper]</font>](https://github.com/deep-optimization/ScaleKD).[<font color="DodgerBlue">[Code]</font>](https://github.com/deep-optimization/ScaleKD).<br> 
<!-- <blockquote> -->
+ KernelWarehouse: Rethinking the Design of Dynamic Convolution.<br> Chao Li\* and Anbang Yao\#.<br><em>**International Conference on Machine Learning (ICML)**</em>, 2024.<br>[<font color="DodgerBlue">[Paper]</font>](https://arxiv.org/abs/2406.07879).[<font color="DodgerBlue">[Code]</font>](https://github.com/OSVAI/KernelWarehouse).<br> 
<!-- <blockquote> -->
+ Small Scale Data-Free Knowledge Distillation.<br> He Liu\*\+, Yikai Wang\*\+, Huaping Liu, Fuchun Sun and Anbang Yao\#.<br><em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2024.<br> [<font color="DodgerBlue">[Paper]</font>](https://arxiv.org/abs/2406.07876).[<font color="DodgerBlue">[Code]</font>](https://github.com/OSVAI/SSD-KD).<br> 
<!--</blockquote> -->

**2023**
<!-- <blockquote> -->
+ Augmentation-free Dense Contrastive Distillation for Efficient Semantic Segmentation.<br> Jiawei Fan\*, Chao Li\*, Xiaolong Liu\*, Meina Song and Anbang Yao\#.<br><em>**Conference on Neural Information Processing Systems (NeurIPS)**</em>, 2023.<br> [<font color="DodgerBlue">[Paper]</font>](https://openreview.net/pdf?id=caUhYUVsLl).[<font color="DodgerBlue">[Code]</font>](https://github.com/OSVAI/Af-DCD).<br> 
<!--</blockquote> -->
<!-- <blockquote> -->
+ Ske2Grid: Skeleton-to-Grid Representation Learning for Action Recognition.<br> Dongqi Cai\*, Yangyuxuan Kang\*, Anbang Yao\# and Yurong Chen.<br><em>**International Conference on Machine Learning (ICML)**</em>, 2023.<br> [<font color="DodgerBlue">[Paper]</font>](https://proceedings.mlr.press/v202/cai23c/cai23c.pdf).[<font color="DodgerBlue">[Code]</font>](https://github.com/OSVAI/Ske2Grid).<br> 
<!--</blockquote> -->
<!-- <blockquote> -->
+ NORM: Knowledge Distillation via N-to-One Representation Matching.<br> Xiaolong Liu\*, Lujun Li\*, Chao Li\* and Anbang Yao\#.<br><em>**International Conference on Learning Representations (ICLR)**</em>, 2023.<br> [<font color="DodgerBlue">[Paper]</font>](https://openreview.net/pdf?id=CRNwGauQpb6).[<font color="DodgerBlue">[Code]</font>](https://github.com/OSVAI/NORM).<br> 
<!--</blockquote> -->
<!--</blockquote> -->
+ 3D Human Pose Lifting with Grid Convolution.<br> Yangyuxuan Kang\*, Yuyang Liu\*, Anbang Yao\#, Shandong Wang and Enhua Wu.<br><em>**AAAI Conference on Artificial Intelligence (AAAI)**</em>, 2023 (<font color="Crimson">Oral</font>).<br> [<font color="DodgerBlue">[Paper]</font>](https://arxiv.org/pdf/2302.08760.pdf).[<font color="DodgerBlue">[Code]</font>](https://github.com/OSVAI/GridConv).<br>
<!--</blockquote> -->

<!-- <blockquote> -->
+ Compacting Binary Neural Networks by Sparse Kernel Selection.<br> Yikai Wang\*, Wenbing Huang, Yinpeng Dong, Fuchun Sun and Anbang Yao\#.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2023.<br> [<font color="DodgerBlue">[Paper]</font>](https://arxiv.org/pdf/2303.14470.pdf).[<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>
<!--</blockquote> -->

**2022**<!-- <blockquote> -->
+ Omni-Dimensional Dynamic Convolution.<br> Chao Li\*, Aojun Zhou and Anbang Yao\#.<br><em>**International Conference on Learning Representations (ICLR)**</em>, 2022 (<font color="Crimson">Spotlight</font>).<br> [<font color="DodgerBlue">[Paper]</font>](https://openreview.net/forum?id=DmpCfq6Mg39&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)).[<font color="DodgerBlue">[Code]</font>](https://github.com/OSVAI/ODConv).<br>
<!--</blockquote> -->

<!-- <blockquote> -->
+ OANet: Learning Two-View Correspondences and Geometry Using Order-Aware Network.<br> Jiahui Zhang\*\+, Dawei Sun\*\+, Zixin Luo, Anbang Yao, Hongkai Chen, Lei Zhou, Tianwei Shen, Yurong Chen, Long Quan and Hongen Liao.<br> <em>**IEEE Trans. on Pattern Analysis and Machine Intelligence**</em>, vol 44(6), pages 3110–3122, 2022.<br> [<font color="DodgerBlue">[Paper]</font>](https://yaoanbang.github.io/). [<font color="DodgerBlue">[Code]</font>](https://github.com/zjhthu/OANet).<br> 
<!-- </blockquote> -->

**2021**

<!-- <blockquote> -->
+ Dynamic Normalization and Relay for Video Action Recognition.<br> Dongqi Cai\*\+, Anbang Yao\+\# and Yurong Chen.<br> <em>**Conference on Neural Information Processing Systems (NeurIPS)**</em>, 2021.<br> [<font color="DodgerBlue">[Paper]</font>](https://proceedings.neurips.cc/paper/2021/hash/5bd529d5b07b647a8863cf71e98d651a-Abstract.html). [<font color="DodgerBlue">[Code]</font>](https://github.com/caidonkey/dnr).<br>
<!--</blockquote> -->

<!-- <blockquote> -->
+ Sub-bit Neural Networks: Learning to Compress and Accelerate Binary Neural Networks.<br> Yikai Wang\*, Yi Yang, Fuchun Sun and Anbang Yao\#.<br> <em>**IEEE International Conference on Computer Vision (ICCV)**</em>, 2021.<br> [<font color="DodgerBlue">[Paper]</font>](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Sub-Bit_Neural_Networks_Learning_To_Compress_and_Accelerate_Binary_Neural_ICCV_2021_paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/yikaiw/SNN).<br>
<!--</blockquote> -->

**2020**

<!--+ Explicit Residual Descent for 3D Human Pose Estimation from 2D Joint Locations.<br> Yangyuxuan Kang\*+, Anbang Yao\+\#, Shandong Wang, Ming Lu, Yurong Chen and Enhua Wu.<br> <em>**British Machine Vision Conference (BMVC)**</em>, 2020.<br> [<font color="DodgerBlue">[Paper]</font>](https://www.bmvc2020-conference.com/assets/papers/0151.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/ky66111/ERD_3DPose).<br>-->
<!--+ Learning Deep Multimodal Feature Representation with Asymmetric Multi-layer Fusion.<br> Yikai Wang\*, Fuchun Sun, Ming Lu and Anbang Yao\#.<br> <em>**ACM International Conference on Multimedia (ACM MM)**</em>, 2020.<br> [<font color="DodgerBlue">[Paper]</font>](https://dl.acm.org/doi/10.1145/3394171.3413621). [<font color="DodgerBlue">[Code]</font>](https://github.com/yikaiw/AsymFusion).<br>-->
+ Knowledge Transfer via Dense Cross-layer Mutual-distillation.<br> Anbang Yao\+\# and Dawei Sun\*+.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2020.<br> [<font color="DodgerBlue">[Paper]</font>](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600290.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/sundw2014/DCM).<br>
+ Resolution Switchable Networks for Runtime Efficient Image Classification.<br> Yikai Wang\*, Fuchun Sun, Duo Li\* and Anbang Yao\#.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2020.<br> [<font color="DodgerBlue">[Paper]</font>](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600528.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/yikaiw/RS-Nets).<br>
+ PSConv: Squeezing Feature Pyramid into One Compact Poly-Scale Convolutional Layer.<br> Duo Li\*, Anbang Yao\# and Qifeng Chen.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2020.<br> [<font color="DodgerBlue">[Paper]</font>](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660613.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/d-li14/PSConv).<br>
<!--+ Learning to Learn Parameterized Classification Networks for Scalable Input Images.<br> Duo Li\*, Anbang Yao\# and Qifeng Chen.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2020.<br> [<font color="DodgerBlue">[Paper]</font>](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123740018.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/d-li14/SAN).<br>-->
<!--+ Pointly-supervised Scene Parsing with Uncertainty Mixture.<br> Hao Zhao\*, Ming Lu\*, Anbang Yao, Yiwen Guo, Yurong Chen and Li Zhang.<br> <em>**Computer Vision and Image Understanding**</em>, vol 200, 103040, 2020.<br> [<font color="DodgerBlue">[Paper]</font>](https://www.sciencedirect.com/science/article/pii/S1077314220300904). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>-->
<!--+ Learning to Draw Sight Lines.<br> Hao Zhao\*, Ming Lu\*, Anbang Yao, Yurong Chen and Li Zhang.<br> <em>**International Journal of Computer Vision**</em>, vol 128(5), pages 1076–1100, 2020.<br> [<font color="DodgerBlue">[Paper]</font>](https://link.springer.com/article/10.1007/s11263-019-01263-4). [<font color="DodgerBlue">[Demo]</font>](https://www.youtube.com/watch?v=81RZvvBv_fw).<br>-->

**2019**

+ Learning Two-View Correspondences and Geometry Using Order-Aware Network.<br> Jiahui Zhang\*\+, Dawei Sun\*\+, Zixin Luo, Anbang Yao\#, Lei Zhou, Tianwei Shen, Yurong Chen, Long Quan and Hongen Liao.<br> <em>**IEEE International Conference on Computer Vision (ICCV)**</em>, 2019.<br> [<font color="DodgerBlue">[Paper]</font>](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Learning_Two-View_Correspondences_and_Geometry_Using_Order-Aware_Network_ICCV_2019_paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/zjhthu/OANet).<br> [<font color="Crimson">Winner of the Image Matching Workshop Challenge at CVPR 2019</font>](https://image-matching-workshop.github.io/leaderboard/)<br> [<font color="Crimson"> Among Most Influential ICCV Papers in Google Scholar Metrics 2023 </font>](https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=Umlb1kMURG4J.2023&vq=en&cstart=160)<br> [<font color="Crimson"> Among Most Influential ICCV Papers in Google Scholar Metrics 2024 </font>](https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=Umlb1kMURG4J.2024&vq=en&cstart=200)<br>
+ A Closed-form Solution to Universal Style Transfer.<br> Ming Lu\*, Hao Zhao\*, Anbang Yao\#, Yurong Chen, Feng Xu and Li Zhang.<br> <em>**IEEE International Conference on Computer Vision (ICCV)**</em>, 2019.<br> [<font color="DodgerBlue">[Paper]</font>](https://openaccess.thecvf.com/content_ICCV_2019/papers/Lu_A_Closed-Form_Solution_to_Universal_Style_Transfer_ICCV_2019_paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/lu-m13/OptimalStyleTransfer).<br>
+ HBONet: Harmonious Bottleneck on Two Orthogonal Dimensions.<br> Duo Li\*\+, Aojun Zhou\*\+ and Anbang Yao\#.<br> <em>**IEEE International Conference on Computer Vision (ICCV)**</em>, 2019.<br> [<font color="DodgerBlue">[Paper]</font>](https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_HBONet_Harmonious_Bottleneck_on_Two_Orthogonal_Dimensions_ICCV_2019_paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/d-li14/HBONet).<br>
+ Deeply-supervised Knowledge Synergy.<br> Dawei Sun\*\+, Anbang Yao\+\#, Aojun Zhou\* and Hao Zhao\*.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2019.<br> [<font color="DodgerBlue">[Paper]</font>](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Deeply-Supervised_Knowledge_Synergy_CVPR_2019_paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/sundw2014/DKS).<br>

**2018**

+ Efficient Semantic Scene Completion Network with Spatial Group Convolution.<br> Jiahui Zhang\*, Hao Zhao\*, Anbang Yao\#, Yurong Chen, Li Zhang and Hongen Liao.<br> <em>**European Conference on Computer Vision (ECCV)**</em>, 2018 (<font color="Crimson">Oral</font>).<br> [<font color="DodgerBlue">[Paper]</font>](https://openaccess.thecvf.com/content_ECCV_2018/papers/Jiahui_Zhang_Efficient_Semantic_Scene_ECCV_2018_paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/zjhthu/SGC-Release).<br>
+ Explicit Loss-Error-Aware Quantization for Low-Bit Deep Neural Networks.<br> Aojun Zhou\*\+, Anbang Yao\+\#, Kuan Wang\* and Yurong Chen.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2018.<br> [<font color="DodgerBlue">[Paper]</font>](https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Explicit_Loss-Error-Aware_Quantization_CVPR_2018_paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>

**2017**

+ Incremental Network Quantization: Towards Lossless CNNs with Low-Precision Weights.<br> Aojun Zhou\*\+, Anbang Yao\+\#, Yiwen Guo\+, Lin Xu and Yurong Chen.<br> <em>**International Conference on Learning Representations (ICLR)**</em>, 2017.<br> [<font color="DodgerBlue">[Paper]</font>](https://arxiv.org/abs/1702.03044). [<font color="DodgerBlue">[Code]</font>](https://github.com/AojunZhou/Incremental-Network-Quantization).<br>[<font color="Crimson"> Among Most Influential ICLR Papers in Google Scholar Metrics 2021 </font>](https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=0032SoU2xY4J.2021&vq=en&cstart=60)<br> [<font color="Crimson"> Among Most Influential ICLR Papers in Google Scholar Metrics 2022 </font>](https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=0032SoU2xY4J.2022&vq=en&cstart=60)<br>
<!--+ Decoder Network over Lightweight Reconstructed Feature for Fast Semantic Style Transfer.<br> Ming Lu\*, Hao Zhao\*, Anbang Yao\#, Feng Xu, Yurong Chen and Li Zhang.<br> <em>**IEEE International Conference on Computer Vision (ICCV)**</em>, 2017.<br> [<font color="DodgerBlue">[Paper]</font>](https://openaccess.thecvf.com/content_ICCV_2017/papers/Lu_Decoder_Network_Over_ICCV_2017_paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>-->
+ RON: Reverse Connection with Objectness Prior Networks for Object Detection.<br> Tao Kong\*, Fuchun Sun, Anbang Yao\#, Huaping Liu, Ming Lu\* and Yurong Chen.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2017.<br> [<font color="DodgerBlue">[Paper]</font>](https://arxiv.org/abs/1707.01691). [<font color="DodgerBlue">[Code]</font>](https://github.com/taokong/RON).<br>
<!--+ Physics Inspired Optimization on Semantic Transfer Features: An Alternative Method for Room Layout Estimation.<br> Hao Zhao\*, Ming Lu\*, Anbang Yao\#, Yurong Chen and Li Zhang.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2017.<br> [<font color="DodgerBlue">[Paper]</font>](https://arxiv.org/abs/1707.00383). [<font color="DodgerBlue">[Code]</font>](https://sites.google.com/view/st-pio/).<br>-->
+ Network Sketching: Exploiting Binary Structure in Deep CNNs.<br> Yiwen Guo, Anbang Yao, Hao Zhao\* and Yurong Chen.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2017.<br> [<font color="DodgerBlue">[Paper]</font>](https://arxiv.org/abs/1706.02021). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ Learning Supervised Scoring Ensemble for Emotion Recognition in the Wild.<br> Ping Hu, Dongqi Cai, Shandong Wang, Anbang Yao\# (<font color="DodgerBlue">project leader, conceived the idea and project</font>) and Yurong Chen.<br> <em>**ACM International Conference on Multimodal Interaction (ACM ICMI)**</em>, 2017 (<font color="Crimson">Oral</font>).<br>[<font color="DodgerBlue">[Paper]</font>](https://dl.acm.org/doi/10.1145/3136755.3143009). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>[<font color="Crimson">Winner of EmotiW-AFEW 2017, out of 100+ Teams</font>](https://sites.google.com/site/emotiwchallenge/)<br>

**2016**

+ Dynamic Network Surgery for Efficient DNNs.<br> Yiwen Guo\*, Anbang Yao\# and Yurong Chen.<br> <em>**Conference on Neural Information Processing Systems (NeurIPS)**</em>, 2016.<br> [<font color="DodgerBlue">[Paper]</font>](https://papers.nips.cc/paper/2016/file/2823f4797102ce1a1aec05359cc16dd9-Paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://github.com/yiwenguo/Dynamic-Network-Surgery).<br>[<font color="Crimson"> Among Most Influential NeurIPS Papers in Google Scholar Metrics 2021</font>](https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=eqYFflc_uhEJ.2021&vq=en&cstart=60)<br>
+ HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection.<br> Tao Kong\*, Anbang Yao\#, Yurong Chen and Fuchun Sun.<br> <em>**IEEE Conference on Computer Vision and Pattern Recognition (CVPR)**</em>, 2016 (<font color="Crimson">Spotlight</font>).<br> [<font color="DodgerBlue">[Paper]</font>](https://openaccess.thecvf.com/content_cvpr_2016/papers/Kong_HyperNet_Towards_Accurate_CVPR_2016_paper.pdf). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>[<font color="Crimson"> Among Most Influential CVPR Papers in Google Scholar Metrics 2021</font>](https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=FXe-a9w0eycJ.2021&vq=en&cstart=140)<br>
+ HoloNet: Towards Robust Emotion Recognition in the Wild.<br> Anbang Yao\+\#, Dongqi Cai\+, Ping Hu\+, Shandong Wang\+, Liang Sha\+ and Yurong Chen.<br> <em>**ACM International Conference on Multimodal Interaction (ACM ICMI)**</em>, 2016 (<font color="Crimson">Oral</font>).<br> [<font color="DodgerBlue">[Paper]</font>](https://dl.acm.org/doi/10.1145/2993148.2997639). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>[<font color="Crimson">1<sup>st</sup> Runner-up of EmotiW-AFEW 2016, out of ~100 Teams</font>](https://sites.google.com/site/emotiw2016/).<br>

**2015 and before**

+ Capturing AU-Aware Facial Features and Their Latent Relations for Emotion Recognition in the Wild.<br> Anbang Yao\+\#, Junchao Shao\*\+, Ningning Ma\*\+ and Yurong Chen.<br> <em>**ACM International Conference on Multimodal Interaction (ACM ICMI)**</em>, 2015 (<font color="Crimson">Oral</font>).<br> [<font color="DodgerBlue">[Paper]</font>](https://dl.acm.org/doi/10.1145/2818346.2830585). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>[<font color="Crimson">Winner of EmotiW-AFEW 2015, out of 75 Teams</font>](https://cs.anu.edu.au/few/emotiw2015.html).<br>
+ Robust Face Representation Using Hybrid Spatial Feature Interdependence Matrix.<br> Anbang Yao\# and Shan Yu.<br> <em>**IEEE Trans. on Image Processing**</em>, vol 22(8), pages 3247–3259, 2013.<br> [<font color="DodgerBlue">[Paper]</font>](https://ieeexplore.ieee.org/document/6459600). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ A Compact Association of Particle Filtering and Kernel Based Object Tracking.<br> Anbang Yao\#, Xinggang Lin, Guijin Wang and Shan Yu.<br> <em>**Pattern Recognition**</em>, vol 45(7), pages 2584-2597, 2012.<br> [<font color="DodgerBlue">[Paper]</font>](https://www.sciencedirect.com/science/article/pii/S0031320312000374). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ An Incremental Bhattacharyya Dissimilarity Measure for Particle Filtering.<br> Anbang Yao\#, Guijin Wang, Xinggang Lin and Xiujuan Chai.<br> <em>**Pattern Recognition**</em>, vol 43(4), pages 1244-1256, 2010.<br> [<font color="DodgerBlue">[Paper]</font>](https://www.sciencedirect.com/science/article/pii/S0031320309003689). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>
+ Kernel Based Articulated Object Tracking with Scale Adaptation and Model Update.<br> Anbang Yao\#, Guijin Wang, Xinggang Lin and Hao Wang.<br> <em>**IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP)**</em>, 2008.<br> [<font color="DodgerBlue">[Paper]</font>](https://ieeexplore.ieee.org/document/4517767). [<font color="DodgerBlue">[Code]</font>](https://yaoanbang.github.io/).<br>

Some Old Manuscripts (Works Done at Intel)  
=====

+ Explicit Connection Distillation.<br> Lujun Li\*\+, Yikai Wang\*\+, Anbang Yao\+\#, Yi Qian, Xiao Zhou and Ke He.<br><em>**ICLR 2021 submission**</em>.<br> [<font color="DodgerBlue">[Manuscript]</font>](https://openreview.net/pdf?id=yOkSW62hqq2).<br> 
+ Weights Having Stable Signs Are Important: Finding Primary Subnetworks and Kernels to Compress Binary Weight Networks.<br> Zhaole Sun\* and Anbang Yao\#.<br><em>**ICLR 2021 submission**</em>.<br> [<font color="DodgerBlue">[Manuscript]</font>](https://openreview.net/pdf?id=B9nDuDeanHK).<br>
+ SnapQuant: A Probabilistic and Nested Parameterization for Binary Networks.<br> Kuan Wang\*, Hao Zhao\*, Anbang Yao\#, Aojun Zhou\*, Dawei Sun\* and Yurong Chen.<br><em>**ICLR 2019 submission**</em>.<br> [<font color="DodgerBlue">[Manuscript]</font>](https://openreview.net/pdf?id=B1ePui0ctQ).<br>

Current and Previous Interns
=====

<!--+I am really fortunate to be working with these amazingly talented students -->

+ [Jiawei Fan](https://jwfandl.github.io/) (Beijing University of Posts and Telecommunications)
+ Miao Song (CAS-IA)
+ [He Liu](https://github.com/liuhe1305) (Tsinghua University)
+ [Yangyuxuan Kang](https://github.com/kyang-06) (CAS-IS)
+ [Yikai Wang](https://scholar.google.com/citations?user=MnW5aegAAAAJ&hl=en) (Tsinghua University)
+ [Chao Li](https://openreview.net/profile?id=~Chao_Li16) (CAS-IA)
+ [Yuyang Liu](https://scholar.google.com/citations?user=0ROQMVcAAAAJ&hl=en) (Tsinghua University)
+ [Zhaole Sun](https://scholar.google.com/citations?user=onTsdhYAAAAJ&hl=en) (Tsinghua University) <!--+ Lujun Li (CAS-IA)-->
+ [Ming Lu](https://github.com/lu-m13) (Tsinghua University)
+ [Hao Zhao](https://scholar.google.com/citations?user=ygQznUQAAAAJ&hl=zh-CN) (Tsinghua University)
+ Duo Li (Tsinghua University)
+ [Dawei Sun](https://scholar.google.com/citations?user=JwuiGckAAAAJ&hl=zh-CN) (Tsinghua University)
+ [Aojun Zhou](https://scholar.google.com/citations?user=cC8lXi8AAAAJ&hl=zh-CN) (CAS-IA) 
+ [Jiahui Zhang](https://scholar.google.com/citations?user=l8YDfhgAAAAJ&hl=en) (Tsinghua University)
+ [Kuan Wang](https://scholar.google.com/citations?user=sGtYJngAAAAJ&hl=en) (Tsinghua University)
+ [Tao Kong](https://scholar.google.com/citations?user=kSUXLPkAAAAJ&hl=en) (Tsinghua University) 
+ [Wenbing Huang](https://scholar.google.com/citations?user=0yNkmO4AAAAJ&hl=zh-CN) (Tsinghua University) 
+ Yun Ren (Beihang University) 
+ Yao Cheng (Peking University) 
+ Peixian Hu (Tsinghua University) 
+ [Ruoyan Wang](https://www.linkedin.com/in/ruoyan-wang) (Dalian University of Technology) 
+ Yuhang Wang (CAS-IA)
+ Yunlong Bian (Beijing University of Posts and Telecommunications) 
+ [Ningning Ma](https://scholar.google.com/citations?user=vOAzYlcAAAAJ&hl=en&oi=sra) (Tsinghua University) 
+ Junchao Shao (Beihang University) 
+ [Yiwen Guo](https://scholar.google.com/citations?user=oi_lEwYAAAAJ&hl=en) (Tsinghua University)

Awards
=====

+ Notable Area Chair, NeurIPS 2024
+ CTO Recognition of exceptional contributions (31 sparse and low-bit AI inference IPs) to the Intel Core Ultra (code-named Meteor Lake) for laptops, 2023.
+ Top (a.k.a. Outstanding) Reviewer Award, NeurIPS 2022
+ Eureka Award 2022, Top-1 Innovator of Intel Labs (had 10 PCT/US patent applications approved in a single quarter), 1 out of ~800 Research Scientists of Intel Labs
+ 6 Intel China Quarterly Awards in 2017~2022, for great technical impacts to Intel China business
+ 1 Outstanding Invention Award in 2020, for strong merits to future Intel AI HW designs
+ Top Reviewer Award, NeurIPS 2019
+ Intel Innovator 2018, 1 out of ~11800 Employees of Intel China, first and only winner employee of Intel China so far 
+ Intel China Employee of the Year Award 2017 	
+ Top-1 Inventor of Intel Labs 2017 (had 34 PCT/US patent applications approved in a single year, keeping the highest record so far), 1 out of ~800 Research Scientists of Intel Labs 
+ Intel i360 Design Hero Award 2017, Highest Annual Business Award of Intel IoTG Asian Region 
+ Intel China Award 2017/2016, Highest Annual Team Award of Intel China 
+ Gordy Award 2016/2015/2014 (named after Intel's co-founder Gordon Earle Moore), Highest Annual Research Award of Intel Labs
+ Tsinghua Friendship-JiangZhen Scholarship 2009, Highest Scholarship in School of Information Science and Technology 
+ Tsinghua Friendship-Toshiba Scholarship 2008, First Class	
+ Tsinghua Friendship-AHaiFa Scholarship 2005, First Class

Academic Service
=====

+ Conference (Senior) Program Committee Member/Area Chair or Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, AAAI, BMVC, WACV, ACCV, ICMI, etc.
+ Journal Reviewer: IEEE-TPAMI, IJCV, IEEE-TNNLS, IEEE-TIP, IEEE-TSMC, IEEE-TC, etc.

